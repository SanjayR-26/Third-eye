# Third-eye
Third-Eye - A completely user-friendly, AI & Computer vision based goggles for visually impaired people, with convenient user modes and a voice assistant 
Goggle can also be controlled with hand gestures.

# Features
- Companion Mode 
- Live update mode – Natural Scene recognition, Object detection, face recognition, People emotions.
- Walking and Reading assistant [Offline modes] – Object detection, Traffic sign detection, WalkSafe Mode, Text recognition, Currency Recognition.
- Safety mode 

In the world of growing technologies some of us are not getting the development that we need to get from those technologies So, we propose this project as an optimal solution to help people in need of a visual assistant. The idea is to develop an app that will connect to the smart glasses which has a camera, microphone, and speaker where the visual and audio data is transmitted to the app and processed in the phone connected and receive back the output and speak it out through the speaker on the glasses. By doing this we don’t need to limit the technology and features we can offer into the device just because of the limitation of hardware and we can provide a limitless number of helpful features for every group of people like providing assistance for travelers, elderly people, visually impaired and etc. we can help people with translating the boards in different languages (also translate sign languages), Read and summarize books which can be very helpful for Visually impaired people and can integrate technologies like Object detection, Face recognition, Optical Character Recognition (OCR), Machine learning and computer vision technologies to help people with real-world problems in a technologically advanced way and hence we are going to integrate all the engines inside an mobile app we are going to have a complete freedom to add pretty much any feature with at most accuracy and efficiency and the users will have a completely customizable device through their device dashboards.
We have developed a device that uses Advanced computer vision engines and multi layered neural networks to assist the people and guide them through the toughest situations of their life by capturing the visual data around the user and help them to read, recognize people, recognize currency, GPS tracking or cross the road without assistance. Which helps them to live more independently rather than always depending on someone’s help. 
We have incorporated various technologies and various sensors to digitally transform the users surrounding into something consumable by the user. The experimental results on the prototype which is performed on various challenging scenes demonstrate that our approach is effective in image sequence with important camera movement, including noise and low-resolution data and achieves high accuracy, while being computational efficient.


# Due to commercial reasons couldn't post the code here.
